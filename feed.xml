<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://victor-navarro.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://victor-navarro.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-01-25T20:12:34+00:00</updated><id>https://victor-navarro.github.io/feed.xml</id><title type="html">victor_navarro</title><subtitle></subtitle><entry><title type="html">new year new me</title><link href="https://victor-navarro.github.io/blog/2024/new-year-new-me/" rel="alternate" type="text/html" title="new year new me"/><published>2024-01-22T16:40:16+00:00</published><updated>2024-01-22T16:40:16+00:00</updated><id>https://victor-navarro.github.io/blog/2024/new-year-new-me</id><content type="html" xml:base="https://victor-navarro.github.io/blog/2024/new-year-new-me/"><![CDATA[<p>It’s been a while since I’ve updated my personal webpage, and whilst reinstalling Jekyll, I though I’d try a new template. Like with most things in life, less is more, so here’s my attempt at being even more minimalistic.</p> <p>In trying to migrate to this system, I’ll likely lose some of the old posts. I guess that’s a lesson to use more robust tools in the future.</p> <p>I’ll have to dig up some very old jupyter notebooks…</p>]]></content><author><name></name></author><summary type="html"><![CDATA[starting anew]]></summary></entry><entry><title type="html">mentimeter</title><link href="https://victor-navarro.github.io/blog/2024/mentimeter/" rel="alternate" type="text/html" title="mentimeter"/><published>2024-01-20T00:00:00+00:00</published><updated>2024-01-20T00:00:00+00:00</updated><id>https://victor-navarro.github.io/blog/2024/mentimeter</id><content type="html" xml:base="https://victor-navarro.github.io/blog/2024/mentimeter/"><![CDATA[<p>I used <a href="https://www.mentimeter.com/">Mentimeter</a> for the first time over the last research away day @ Cardiff. Within the same week, I used it again to gauge the overall knowledge level of my audience during a web seminar.</p> <p>I presented some of the work I’ve done with Rob and Dom during the seminar; the work tends to have a ton of math, but I was lucky the audience were a bunch of nerds in our field.</p> <center><img src="/assets/img/mentimeter-palm.png" width="80%"/></center> <p><br/></p> <p>The talk went well, although I forgot to ask how much more confused people were after my talk.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[a double-edged tool]]></summary></entry><entry><title type="html">calmr package</title><link href="https://victor-navarro.github.io/blog/2023/calmr/" rel="alternate" type="text/html" title="calmr package"/><published>2023-01-22T00:00:00+00:00</published><updated>2023-01-22T00:00:00+00:00</updated><id>https://victor-navarro.github.io/blog/2023/calmr</id><content type="html" xml:base="https://victor-navarro.github.io/blog/2023/calmr/"><![CDATA[<center><img src="/assets/img/calmr.png" width="30%"/></center> <p><br/></p> <p>I am developing an R package that includes some cool associative learning models. You can find it in its <a href="https://github.com/victor-navarro/calmr">github repository</a>.</p> <p>Better yet, you can access its own webpage with documentation and examples at <a href="https://victornavarro.org/calmr/">https://victornavarro.org/calmr/</a></p> <p>Even betterer, you can access a <a href="https://victor-navarro.shinyapps.io/calmr_app/">Shiny app</a> that allows to do simulations using a fairly simple syntax.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[canonical associative learning models in R]]></summary></entry><entry><title type="html">a HeiDI demo</title><link href="https://victor-navarro.github.io/blog/2021/heidi/" rel="alternate" type="text/html" title="a HeiDI demo"/><published>2021-02-23T00:00:00+00:00</published><updated>2021-02-23T00:00:00+00:00</updated><id>https://victor-navarro.github.io/blog/2021/heidi</id><content type="html" xml:base="https://victor-navarro.github.io/blog/2021/heidi/"><![CDATA[<p>2024 Victor says: The notebook below is very outdated. Please head to the calmr section if you want to use an intelligible (and correct) version of the model.</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/HeiDI_demo.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="associative"/><category term="learning"/><category term="model"/><summary type="html"><![CDATA[abuelito dime tu]]></summary></entry><entry><title type="html">creating cancer</title><link href="https://victor-navarro.github.io/blog/2020/cancer_dcgan/" rel="alternate" type="text/html" title="creating cancer"/><published>2020-12-29T00:00:00+00:00</published><updated>2020-12-29T00:00:00+00:00</updated><id>https://victor-navarro.github.io/blog/2020/cancer_dcgan</id><content type="html" xml:base="https://victor-navarro.github.io/blog/2020/cancer_dcgan/"><![CDATA[<p>In what follows, I train a generative adversarial network (GAN) to generate fake images of breast cancer tissue. GANs are pretty cool, and so I wanted to dip my toes on them.</p> <p>This one follows a basic GAN <a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html">tutorial</a> to the point. All credit goes to them.</p> <p>2024 Victor says: I could not manage to recover the notebook below. Sorry! But, it is exactly what you would have expected to find.</p> ]]></content><author><name></name></author><category term="categorization"/><category term="generative"/><category term="adversarial"/><category term="networks"/><category term="convolutional"/><category term="cancer"/><summary type="html"><![CDATA[why would you do that?]]></summary></entry><entry><title type="html">on fast and slow errors</title><link href="https://victor-navarro.github.io/blog/2020/slow-errors/" rel="alternate" type="text/html" title="on fast and slow errors"/><published>2020-08-03T00:00:00+00:00</published><updated>2020-08-03T00:00:00+00:00</updated><id>https://victor-navarro.github.io/blog/2020/slow-errors</id><content type="html" xml:base="https://victor-navarro.github.io/blog/2020/slow-errors/"><![CDATA[<p>I try really hard, but I still struggle when it comes to convolving distributions entirely in my head. Apparently, the presence of slow errors is a common prediction for the <a href="https://en.wikipedia.org/wiki/Two-alternative_forced_choice#Drift-diffusion_model">drift diffusion model</a>. Here’s a code-adventure showing it is indeed the case.</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/slow_errors.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="drift"/><category term="difusion"/><category term="model"/><category term="categorization"/><category term="jupyter"/><summary type="html"><![CDATA[A counterintuitive prediction]]></summary></entry><entry><title type="html">every paper is an iceberg</title><link href="https://victor-navarro.github.io/blog/2020/iceberg/" rel="alternate" type="text/html" title="every paper is an iceberg"/><published>2020-07-27T00:00:00+00:00</published><updated>2020-07-27T00:00:00+00:00</updated><id>https://victor-navarro.github.io/blog/2020/iceberg</id><content type="html" xml:base="https://victor-navarro.github.io/blog/2020/iceberg/"><![CDATA[<p>You only see the tip of it</p> <p>Here’s a Jupyter notebook that illustrates the modelling I did for a recent paper on <a href="/pubs/human-pigeon-attention/">the attentional profiles of pigeons and humans</a>. Some numerical optimization is done in it, so be patient if you try the live version. You can access live code by clicking this badge <a href="https://mybinder.org/v2/gh/victor-navarro/binder-repo/master?filepath=Recovering%20attention%20from%20GCM.ipynb" target="blank"><img src="https://mybinder.org/badge_logo.svg" alt="Binder"/></a></p> <p>Otherwise, a static view of the code is shown below.</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/iceberg.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="jupyter"/><category term="code"/><category term="categorization"/><category term="gcm"/><category term="attention"/><summary type="html"><![CDATA[You only see the tip of it]]></summary></entry><entry><title type="html">zeus</title><link href="https://victor-navarro.github.io/blog/2020/code-snippets/" rel="alternate" type="text/html" title="zeus"/><published>2020-07-21T00:00:00+00:00</published><updated>2020-07-21T00:00:00+00:00</updated><id>https://victor-navarro.github.io/blog/2020/code-snippets</id><content type="html" xml:base="https://victor-navarro.github.io/blog/2020/code-snippets/"><![CDATA[<p>An easy way to make tinkerable code is to use <a href="https://jupyter.org/">Jupyter notebooks</a>. I will start posting some code snippets I find useful in my blog entries. More often than not, I only get true understanding from coding. Perhaps wrongly, I assume other people are the same. Here’s an example that I wrote for an undergrad student I’m currently working with. It involves calculating SDT measures for categorization data.</p> <p>You can interact with the code by clicking this badge. <a href="https://mybinder.org/v2/gh/victor-navarro/binder-repo/master?filepath=sdt_categorization.ipynb" target="blank"><img src="https://mybinder.org/badge_logo.svg" alt="Binder"/></a></p> <p>A static view of the code is shown below.</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/sdt_categorization.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div>]]></content><author><name></name></author><category term="jupyter"/><category term="code"/><category term="signal"/><category term="detection"/><category term="theory"/><summary type="html"><![CDATA[the start of something useful]]></summary></entry><entry><title type="html">keeping pigeons close to our hearts</title><link href="https://victor-navarro.github.io/blog/2020/keep-pigeons-close/" rel="alternate" type="text/html" title="keeping pigeons close to our hearts"/><published>2020-07-18T00:00:00+00:00</published><updated>2020-07-18T00:00:00+00:00</updated><id>https://victor-navarro.github.io/blog/2020/keep-pigeons-close</id><content type="html" xml:base="https://victor-navarro.github.io/blog/2020/keep-pigeons-close/"><![CDATA[<p><em>This is a repost of a column that me and Ed Wasserman wrote for APAs Division 25.</em></p> <p>According to the <a href="https://www.cdc.gov/nchs/fastats/leading-causes-of-death.htm">CDC</a>, you are more likely to die from heart disease than from cancer or respiratory diseases. Care-providers and researchers work around the clock to fight this gloomy statistic, developing preventative pharmacological and last-resort invasive therapies. However, the effective deployment of these therapies requires a timely and reliable method for detecting the onset of cardiac disease. If your physician suspects you might be suffering from heart disease, they will likely recommend you get a Myocardial Perfusion SPECT test (or MPS for short). Although this test is highly accurate in determining how well blood is flowing through the heart muscle (the myocardium), the decision of whether you will need treatment ultimately rests on how this test is interpreted by your physician. The bad news is that <a href="https://doi.org/10.1080/17434440.2017.1300057">studies</a> have shown that human interpretation of MPS tests is fairly subjective: individual observers are only moderately accurate (they are correct 85% of the time), and inter-observer agreement is poor (different observers agree only 87% of the time).</p> <center><img src="/assets/img/cardiocol1.png"/></center> <p><em>Figure 1. Many slices of MPS data (left column) are used to reconstruct the heart’s ventricle (top right) and processed into a format your physician can interpret (bottom right).</em>&lt;/span&gt;</p> <p>To avoid this interpretability problem, some researchers have proposed to aid humans’ interpretations <a href="https://dx.doi.org/10.1038%2Fs41568-018-0016-5">using artificial intelligence</a>. In a recent project, we took this proposal one step further, by requesting medical consultation from a feathery friend: the pigeon. In case you missed it, we have previously reported that <a href="https://doi.org/10.1371/journal.pone.0141357">pigeons can proficiently classify mammograms and histology samples of human breast tissue as benign or malignant</a>. This time around, using elementary operant conditioning techniques, <a href="https://doi.org/10.3758/s13420-020-00410-z">we trained pigeons to distinguish between MPS tests from normal of abnormal hearts</a>, which had nominal and low perfusion levels, respectively. Pigeons were initially trained to peck one of two different black-and-white patterns on a touchscreen to report whether the MPS data they were seeing on a computer monitor corresponded with normal or abnormal hearts (Figure 2).</p> <p>In each training session, pigeons were shown individual MPS images across several trials. On each trial, pigeons had to peck the image multiple times. Having ensured pigeons had enough time to study the image, we presented them with two report buttons located on each side of the image. A final peck to either of the report buttons constituted the pigeon’s choice. If the image shown to them was normal and they pecked the “normal” report button, or if the image shown to them was abnormal and they pecked the “abnormal” button, then we rewarded them with food. However, if the pigeons pecked the incorrect button, then no food was given.</p> <center><img src="/assets/img/cardiocol2.png"/></center> <p><em>Figure 2. Normal and abnormal MPS tests were shown as polar plots (left). A pigeon hard at work in the operant chamber (right).</em>&lt;/span&gt;</p> <p>Pigeons succeeded in quickly learning these images, attaining 80% to 85% accuracy. We then set out to discover whether our pigeons could generalize their diagnoses to images they had never seen before. The birds passed this generalization test with flying colors—categorization of novel images was as just accurate as was categorization of familiar images—confirming they had not merely memorized the appropriate response for each image, but rather had acquired true normal/abnormal categories. In a final test, we showed the pigeons black-and-white versions of the same MPS images they had seen in training. Despite these images conveying the identical information as their colored counterparts, pigeons were unable to categorize these images accurately. Clearly, color had played a pivotal part during learning. In a second experiment, a different cohort of pigeons was trained with black-and-white MPS images from the get-go. Although the absence of color information put a dent in the speed with which our pigeons learned to categorize the images, the birds were again able to transfer their performance to novel images with no loss in accuracy. It is worth noting that MPS data are not initially colorized; technicians choose whether to colorize these images, and if so, <a href="https://doi.org/10.1016/j.nuclcard.2006.05.014">which color map to use</a>. <a href="https://doi.org/10.1109/MCG.2007.323435">That decision is not trivial</a>. By keeping pigeons close to our hearts and seeing the world through their eyes, we learned a thing or two about the psychological processes underlying humans’ classification of medical images. By using pigeons as surrogate cardiologists, our pair of experiments proved that the presence of color information makes difficult medical classification tasks such as these easier to learn, but it does not necessarily improve the ability to classify new cases.</p>]]></content><author><name></name></author><category term="categorization"/><category term="medical"/><category term="images"/><category term="pigeon"/><category term="experiment"/><summary type="html"><![CDATA[A general-audience write up of pigeons categorizing human hearts]]></summary></entry><entry><title type="html">have a computer? program an experiment</title><link href="https://victor-navarro.github.io/blog/2019/minimal-setup/" rel="alternate" type="text/html" title="have a computer? program an experiment"/><published>2019-10-20T00:00:00+00:00</published><updated>2019-10-20T00:00:00+00:00</updated><id>https://victor-navarro.github.io/blog/2019/minimal-setup</id><content type="html" xml:base="https://victor-navarro.github.io/blog/2019/minimal-setup/"><![CDATA[<h2 id="psy4020">PSY4020</h2> <p>As a kid, I created my first (and never-hosted) website using <a href="https://en.wikipedia.org/wiki/Microsoft_FrontPage">MS FrontPage</a>. I loved <a href="https://en.wikipedia.org/wiki/The_King_of_Fighters">KOF 1997</a>. Many years later, I had the opportunity to print out my first “Hello, world!” using a Python IDE.</p> <p>However, many undergrads have never interfaced with a command-line interface, and even less have had the opportunity to learn programming. So, it was not surprising to find out some of my students did not know how to implement their laboratory experiments.</p> <h2 id="you-only-need-a-computer-and-a-knack-for-programming">You only need a computer, and a knack for programming</h2> <p>Inspired by the setup we have in our laboratory, I put together a minimal-setup script using Octave and Psychtoolbox, so they could program their experiments. One of the student groups had to run a follow-up experiment on <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3382032/">spatial biases</a>, and we came up with a fairly good script. <a href="https://github.com/victor-navarro/PSY4020/tree/master/spatialBias">Check it out here!</a></p> <p><em>The follow-up was successful, by the way. It turns out you can extinguish spatial biases, if you try.</em></p>]]></content><author><name></name></author><category term="hardware"/><category term="software"/><category term="experiments"/><summary type="html"><![CDATA[a minimal setup to run human experiments in a computer environment.]]></summary></entry></feed>
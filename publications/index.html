<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | victor_navarro </title> <meta name="author" content="Victor M. Navarro"> <meta name="description" content="if you need any of these publications (or their data) just send me an email"> <meta name="keywords" content="academic-website, learning, psychology"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.ico?c6c29525ced1316e819daec1c936442f"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://victor-navarro.github.io/publications/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?bbadb8e3955ca543a14cffbb8e2772a1"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> victor_navarro </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/calm/">calm </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">if you need any of these publications (or their data) just send me an email</p> </header> <article> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mnist-480.webp 480w,/assets/img/publication_preview/mnist-800.webp 800w,/assets/img/publication_preview/mnist-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/mnist.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mnist.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="harding_new_2024" class="col-sm-8"> <div class="title">A new predictive coding model for a more comprehensive account of delusions</div> <div class="author"> Jessica Niamh Harding ,  Noham Wolpe ,  Stefan Peter Brugger , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Victor Navarro, Christoph Teufel, Paul Charles Fletcher' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>The Lancet Psychiatry</em>, Jan 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ratblast-480.webp 480w,/assets/img/publication_preview/ratblast-800.webp 800w,/assets/img/publication_preview/ratblast-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/ratblast.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ratblast.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="navarro_2024_blast" class="col-sm-8"> <div class="title">Enhanced attention in rats following blast-induced traumatic brain injury</div> <div class="author"> Victor M. Navarro ,  Nickolas Boehme ,  Edward A. Wasserman , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Matthew M. Harper' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Heliyon</em>, Jan 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Purpose To evaluate visuo-cognitive sequelae following blast-induced traumatic brain injury in a rat model. Methods Rats were randomly assigned to one of four groups depending on the intensity/quantity of a blast received in a blast chamber: sham (no blast), low intensity (22 psi), medium intensity (26 psi), or three medium intensity blasts (26 psi × 3). After recovery, all subjects were given visual discrimination tasks of increasing complexity, until mastery. After behavioral training, visual function was assessed via spectral-domain optical coherence tomography and pattern electroretinogram, and the extent of retinal damage was quantified via immunohistochemistry of retinal ganglion cells. Results None of the measures assessing visual function revealed significant differences as a function of blast intensity/quantity. Behavioral training did not disclose short-term effects of blast in general motivation or the development of anticipatory responding. No differences in general learning ability and the number of perseverative errors were observed. However, behavioral training found effects of blast in attentional function; relative to controls, subjects that received blasts were faster in learning to attend to informative (over non-informative) cues in the most difficult visual discrimination task. Conclusion Blast exposure in rats resulted in increased attention following blast, with no appreciable deficits in visual function. These results are contrary to what is often reported for human clinical populations; as such, more research bridging methodological differences is necessary.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mice-rgc-480.webp 480w,/assets/img/publication_preview/mice-rgc-800.webp 800w,/assets/img/publication_preview/mice-rgc-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/mice-rgc.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mice-rgc.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="harper_increasing_2024" class="col-sm-8"> <div class="title">Increasing the number and intensity of shock tube generated blast waves leads to earlier retinal ganglion cell dysfunction and regional cell death</div> <div class="author"> Matthew M. Harper ,  Nickolas A. Boehme ,  Laura Dutca , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Victor Navarro' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Experimental Eye Research</em>, Feb 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>The purpose of this study was to examine the effect of a blast exposure generated from a shock tube on retinal ganglion cell (RGC) function and structure. Mice were exposed to one of three blast conditions using a shock tube; a single blast wave of 20 PSI, a single blast wave of 30 PSI, or three blast waves of 30 PSI given on three consecutive days with a one-day inter-blast interval. The structure and function of the retina were analyzed using the pattern electroretinogram (PERG), the optomotor reflex (OMR), and optical coherence tomography (OCT). The in vivo parameters were examined at baseline, and then again 1-week, 4-weeks, and 16-weeks following blast exposure. The number of surviving RGCs was quantified at the end of the study. Analysis of mice receiving a 20 PSI injury showed decreased PERG and OMR responses 16-weeks post blast, without evidence of changed retinal thickness or RGC death. Mice subjected to a 30 PSI injury showed decreased PERG responses 4 weeks and 16 weeks after injury, without changes in the retinal thickness or RGC density. Mice subjected to 30 PSI X 3 blast exposures had PERG deficits 1-week and 4-weeks post exposure. There was also significant change in retinal thickness 1-week and 16-weeks post blast exposure. Mice receiving 30 PSI X 3 blast injuries had regional loss of RGCs in the central retina, but not in the mid-peripheral or peripheral retina. Overall, this study has shown that increasing the number of blast exposures and the intensity leads to earlier functional loss of RGCs. We have also shown regional RGC loss only when using the highest blast intensity and number of blast injuries.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/GT_rats-480.webp 480w,/assets/img/publication_preview/GT_rats-800.webp 800w,/assets/img/publication_preview/GT_rats-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/GT_rats.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="GT_rats.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="navarro_prediction_2023" class="col-sm-8"> <div class="title">Prediction error in models of adaptive behavior</div> <div class="author"> Victor M. Navarro ,  Dominic M. Dwyer ,  and  Robert C. Honey </div> <div class="periodical"> <em>Current Biology</em>, Oct 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Pavlovian conditioning is evident in every species in which it has been assessed, and there is a consensus about its interpretation across behavioral,1,2 brain,3–6 and computational analyses7–11: conditioned behavior reﬂects the formation of a directional associative link from the memory of one stimulus (e.g., a visual stimulus) to another (e.g., food), with learning stopping when there is no error between the prediction generated by the visual stimulus and what happens next (e.g., food). This consensus fails to anticipate the results that we report here. In our experiments with rats, we ﬁnd that arranging predictive (visual stimulus/food) and nonpredictive (food/visual stimulus) relationships produces marked and sustained changes in conditioned behaviors when the visual stimulus is presented alone. Moreover, the type of relationship affects (1) the distribution of conditioned behaviors related to the properties of both food (called goal-tracking) and the visual stimulus (called sign-tracking) and (2) when in the visual stimulus, these two behaviors are evident. These results represent an impetus for a fundamental shift in how Pavlovian conditioning is interpreted: animals learn about the relationship between two stimuli irrespective of the order in which they are presented, but they exhibit this knowledge in different ways. This interpretation and our new results are captured by a recent model of Pavlovian conditioning,12,13 HeiDI, and both are consistent with the need for animals to represent the fact that the impact of a cause (e.g., the ingestion of nutrients or the bite of a predator) can be felt before or after the cause has been perceived.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/gabor-480.webp 480w,/assets/img/publication_preview/gabor-800.webp 800w,/assets/img/publication_preview/gabor-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/gabor.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="gabor.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="odonoghue_its_2022" class="col-sm-8"> <div class="title">It’s not all the same to pigeons: Representations of difference may be shared across species</div> <div class="author"> Ellen M. O’Donoghue ,  Francisca Diaz ,  Victor M. Navarro , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Edward A. Wasserman' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Psychonomic Bulletin &amp; Review</em>, Jun 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Pigeons readily learn and transfer same-different discriminations in a variety of experimental paradigms. However, strategically designed probe tests suggest that they might only represent sameness. Here, we provide the first direct evidence that pigeons also represent difference. We first trained pigeons on a conditional same-different discrimination; then, on probe trials, we replaced either the same-item pair or the different-item pair with a familiar, but ambiguous stimulus. On differentcued probe trials, pigeons’ choices were controlled by sameness: they reliably rejected the same-item pair, but they did not reliably select the different-item pair. Conversely, on same-cued probe trials, pigeons’ choices were controlled by difference: they reliably rejected the different-item pair, but they did not reliably select the same-item pair. Together, these findings demonstrate that pigeons can represent both sameness and difference, providing an important clue to elucidating the evolutionary origins of same-different conceptualization.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/bidirectional-480.webp 480w,/assets/img/publication_preview/bidirectional-800.webp 800w,/assets/img/publication_preview/bidirectional-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/bidirectional.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="bidirectional.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="navarro_bidirectional_2020" class="col-sm-8"> <div class="title">Bidirectional conditioning: Revisiting Asratyan’s ‘alternating’ training technique</div> <div class="author"> Victor M. Navarro ,  and  Edward A. Wasserman </div> <div class="periodical"> <em>Neurobiology of Learning and Memory</em>, May 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>The study of bidirectional conditioning began more than a century ago, yet it has failed to take strong root in psychology and neuroscience. We revisit this topic by exploiting E. A. Asratyan’s alternating procedure of stimulus presentation, in which both forward (e.g., A → B) and backward (e.g., B → A) training trials are concurrently given, in order to analyze their potential interaction. Speciﬁcally, using a two-alternative, forcedchoice task, we trained humans and pigeons to learn associations between stimuli depending on whether they were presented as sample stimuli or choice stimuli. Trials were selected from an associative network in which forward and backward associations between sample and choice stimuli were synergistic (bidirectional network) or from an associative network in which these associations were not synergistic (unidirectional network). Humans were faster to learn associations from the bidirectional network than from the unidirectional network; additionally, they performed poorly on unidirectional trials that allowed for the expression of (incorrect) bidirectional associations. Unlike humans, pigeons showed no evidence of bidirectional associations. The reasons for this species diﬀerence as well as future directions for research deploying Asratyan’s two-way training technique are discussed.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/pigeon-human-attention-480.webp 480w,/assets/img/publication_preview/pigeon-human-attention-800.webp 800w,/assets/img/publication_preview/pigeon-human-attention-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/pigeon-human-attention.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="pigeon-human-attention.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="castro_selective_2020" class="col-sm-8"> <div class="title">Selective and distributed attention in human and pigeon category learning</div> <div class="author"> Leyre Castro ,  Olivera Savic ,  <em>Victor Navarro</em> , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Vladimir M. Sloutsky, Edward A. Wasserman' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Cognition</em>, Nov 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Attention to relevant stimulus features in a categorization task helps to optimize performance. However, the relationship between attention and categorization is not fully understood. For example, even when human adults and young children exhibit comparable categorization behavior, adults tend to attend selectively during learning, whereas young children tend to attend diffusely (Deng &amp; Sloutsky, 2016). Here, we used a comparative approach to investigate the link between attention and categorization in two different species. Given the noteworthy categorization ability of avian species, we compared the attentional profiles of pigeons and human adults. We gave human adults (Experiment 1) and pigeons (Experiment 2) a categorization task that could be learned on the basis of either one deterministic feature (encouraging selective attention) or multiple probabilistic features (encouraging distributed attention). Both humans and pigeons relied on the deterministic feature to categorize the stimuli, albeit humans did so to a much greater degree. Furthermore, computational modeling revealed that most of the adults exhibited maximal selectivity, whereas pigeons tended to distribute their attention among several features. Our findings indicate that human adults focus their attention on deterministic information and filter less predictive information, but pigeons do not. Implications for the underlying brain mechanisms of attention and categorization are discussed.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cardiocol1-480.webp 480w,/assets/img/publication_preview/cardiocol1-800.webp 800w,/assets/img/publication_preview/cardiocol1-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cardiocol1.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cardiocol1.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="navarro_taking_2020" class="col-sm-8"> <div class="title">Taking pigeons to heart: Birds proficiently diagnose human cardiac disease</div> <div class="author"> Victor M. Navarro ,  Edward A. Wasserman ,  and  Piotr Slomka </div> <div class="periodical"> <em>Learning &amp; Behavior</em>, Mar 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>In two experiments, we trained pigeons (Columba livia) to sort visual images (obtained by clinical myocardial perfusion imaging techniques) depicting different degrees of human cardiac disfunction (myocardial hypoperfusion of the left ventricle) into normal and abnormal categories by providing food reward only after correct choice responses. Pigeons proved to be highly proficient at categorizing pseudo-colorized images as well as highly sensitive to the degree of the perfusion deficit depicted in the abnormal images. In later testing, the pigeons completely transferred discriminative responding to novel stimuli, demonstrating that they had fully learned the normal and abnormal categories. Yet, these pigeons failed to transfer discriminative responding to grayscale images containing no color information. We therefore trained a second cohort of pigeons to categorize grayscale image sets from the outset. These birds required substantially more training to achieve similar levels of performance. Yet, they too completely transferred discriminative responding to novel stimuli by relying on both global and local disparities in brightness between the normal and abnormal images. These results confirm that pseudo-colorization can enhance pigeons’ categorization of human cardiac images, a result also found with human observers. Overall, our findings further document the potential of the pigeon as a useful aide in studies of medical image perception.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/categorization-480.webp 480w,/assets/img/publication_preview/categorization-800.webp 800w,/assets/img/publication_preview/categorization-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/categorization.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="categorization.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="navarro_pigeon_2019" class="col-sm-8"> <div class="title">Pigeon category learning: Revisiting the Shepard, Hovland, and Jenkins (1961) tasks.</div> <div class="author"> Victor M. Navarro ,  Ridhi Jani ,  and  Edward A. Wasserman </div> <div class="periodical"> <em>Journal of Experimental Psychology: Animal Learning and Cognition</em>, Apr 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>In a seminal study, Shepard, Hovland, and Jenkins (1961; henceforth SHJ) assessed potential mechanisms involved in categorization learning. To do so, they sequentially trained human participants with 6 different visual categorization tasks that varied in structural complexity. Humans’ exceptionally strong performance on 1 of these tasks (Type 2, organized around exclusive-or relations) could not be solely explained by structural complexity, and has since been considered the hallmark of rule-use in these tasks. In the present project, we concurrently trained pigeons on all 6 SHJ tasks. Our results revealed that the structural complexity of the tasks was highly correlated with group-level performance. Nevertheless, we observed notable individual differences in performance. Two extensions of a prominent categorization model, ALCOVE (Kruschke, 1992), suggested that disparities in the discriminability of the dimensions used to construct the experimental stimuli could account for these differences. Overall, our pigeons’ generally weak performance on the Type 2 task provides no evidence of rule-use on the SHJ tasks. Pigeons thus join monkeys in the contingent of species that solve these categorization tasks solely on the basis of the physical properties of the training stimuli.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/extinction-stimuli-480.webp 480w,/assets/img/publication_preview/extinction-stimuli-800.webp 800w,/assets/img/publication_preview/extinction-stimuli-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/extinction-stimuli.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="extinction-stimuli.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="alfaro_rol_2019" class="col-sm-8"> <div class="title">Rol de Estímulos Asociados a las Claves de Extinción en la Recuperación de Respuesta</div> <div class="author"> Felipe Alfaro ,  Víctor M. Navarro ,  Mario A. Laborda , and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Ronald Betancourt, Gonzalo Miguez, Felipe Alfaro, Víctor M. Navarro, Mario A. Laborda, Ronald Betancourt, Gonzalo Miguez' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>Psykhe (Santiago)</em>, May 2019 </div> <div class="periodical"> Publisher: Pontificia Universidad Católica de Chile </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>:En 2 experimentos se investigó el rol de las claves de extinción (CE), y estímulos asociados a estas, en la readquisición de la tolerancia condicionada al etanol. La ataxia causada por el etanol fue medida en 80 ratas, utilizando planos de deslizamiento en un procedimiento de 5 fases. El primer experimento (que utilizó 4 contextos y 40 ratas) mostró que la presentación del contexto de extinción por sí solo disminuyó la efectividad de la CE para reducir la readquisición de respuesta. El segundo experimento (hecho en un solo contexto, con 40 ratas y con la diferencia de que se usaron 2 estímulos que fueron pareados para algunos sujetos o explícitamente no pareados para otros) mostró que una clave secundaria puede reducir la readquisición, independientemente de si fue pareada con la CE o no. Los resultados de análisis de varianza mixtos y factoriales sugieren que la CE afectaría la recuperación de la respuesta a través de una asociación con el contexto de extinción; sin embargo, una clave de segundo orden, asociada a la CE, no lograría activar dicha asociación.Palabras clave: extinción; condicionamiento clásico; tolerancia a las drogas; etanol; ataxia</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/dimensional-attention-480.webp 480w,/assets/img/publication_preview/dimensional-attention-800.webp 800w,/assets/img/publication_preview/dimensional-attention-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/dimensional-attention.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dimensional-attention.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="vyazovska_pigeons_2018" class="col-sm-8"> <div class="title">Pigeons deploy selective attention to efficiently learn a stagewise multidimensional visual discrimination task.</div> <div class="author"> Olga V. Vyazovska ,  Victor M. Navarro ,  and  Edward A. Wasserman </div> <div class="periodical"> <em>Journal of Experimental Psychology: Animal Learning and Cognition</em>, Apr 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>We trained 8 pigeons (Columba livia) on a stagewise go/no-go visual discrimination task of increasing complexity, to document the dynamics of selective attention. We constructed negative compound stimuli (S-s) on the basis of their overall similarity to a positive compound stimulus (Sϩ) along 4 binary-valued dimensions: shape (circle/square), size (large/small), line orientation (horizontal/vertical), and brightness (dark/light). Starting with 1 Sϩ and 1 S- that differed in all 4 dimensional values, in 3 later steps, we progressively added S-s sharing 1, 2, and finally 3 dimensional values with the Sϩ. Although in the first step the pigeons could have attended to any of the 4 dimensions (separately or together) to solve the discrimination, all of the pigeons attended to only 1 dimension. Furthermore, the pigeons attended to just 1 additional dimension in each of the 3 succeeding steps. Notably, all pigeons discriminated the 4 dimensions in the same order: first brightness, then line orientation, then size, and finally shape. This ordering corresponds with the overall discriminability of the dimensional values for these dimensions observed in prior studies. Pigeons clearly optimized their attentional behavior, selectively and efficiently processing only 1 additional dimension in each stage of discrimination learning.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/extinction-cues-480.webp 480w,/assets/img/publication_preview/extinction-cues-800.webp 800w,/assets/img/publication_preview/extinction-cues-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/extinction-cues.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="extinction-cues.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="quezada_scholz_extinction_2018" class="col-sm-8"> <div class="title">Extinction cues do not reduce recovery of extinguished conditioned fear in humans</div> <div class="author"> Vanetza Quezada Scholz ,  Mario Laborda Rojas ,  Marcela C. Díaz , and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Víctor M. Navarro, Jorge Mallea, Paula Repetto, Gricel Orellana Vidal, Ronald Betancourt' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>International Journal of Psychology and Psychological Therapy</em>, Apr 2018 </div> <div class="periodical"> Accepted: 2019-05-31T15:22:28Z Publisher: Universidad de Almeria </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Repositorio académico de la Universidad de Chile. Tesis, artículos y libros publicados en formato digital con distintos niveles de acceso</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/anticipation-rt-480.webp 480w,/assets/img/publication_preview/anticipation-rt-800.webp 800w,/assets/img/publication_preview/anticipation-rt-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/anticipation-rt.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="anticipation-rt.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="garcia-gallardo_assessing_2017" class="col-sm-8"> <div class="title">Assessing the acquisition of anticipatory responding in the pigeon using reaction time.</div> <div class="author"> Daniel García-Gallardo ,  Víctor M. Navarro ,  and  Edward A. Wasserman </div> <div class="periodical"> <em>Journal of Experimental Psychology: Animal Learning and Cognition</em>, Apr 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>We report a novel method for investigating the acquisition of anticipatory responding in the pigeon. Four pigeons (Columba livia) received food for pecking a starburst target stimulus displayed in the bottom-left or bottom-right portion of a computer screen. The target stimulus was preceded by 1 of 3 fractal images displayed in either the upper-left or upper-right portion of the screen: 1 of the fractals was perfectly correlated with the target appearing in the bottom-left, the second fractal was perfectly correlated with the target appearing in the bottom-right, and the third fractal was uncorrelated with the location of the target. The pigeons learned to anticipate the location of the upcoming target stimulus, because they were faster to peck the target stimulus on trials that involved a predictive fractal than on trials that involved a nonpredictive fractal. In a later phase, we reversed the signaled target location of each of the 2 predictive fractals. After an initial disruption in performance, the pigeons successfully learned the new stimulus assignments, exhibiting the same pattern of responding as during the initial training phase. Overall, the results document the utility of this novel training procedure and further underscore the role that associative processes play in anticipatory responding.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/space-time-480.webp 480w,/assets/img/publication_preview/space-time-800.webp 800w,/assets/img/publication_preview/space-time-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/space-time.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="space-time.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="de_corte_non-cortical_2017" class="col-sm-8"> <div class="title">Non-cortical magnitude coding of space and time by pigeons</div> <div class="author"> Benjamin J. De Corte ,  Victor M. Navarro ,  and  Edward A. Wasserman </div> <div class="periodical"> <em>Current Biology</em>, Dec 2017 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/massive-extinction-480.webp 480w,/assets/img/publication_preview/massive-extinction-800.webp 800w,/assets/img/publication_preview/massive-extinction-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/massive-extinction.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="massive-extinction.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="diaz_effect_2017" class="col-sm-8"> <div class="title">The effect of massive extinction trials on the recovery of human fear conditioning</div> <div class="author"> Marcela C. Díaz ,  Vanetza E. Quezada ,  Víctor M. Navarro , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Mario A. Laborda, Ronald Betancourt' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Revista Mexicana de Psicología</em>, Dec 2017 </div> <div class="periodical"> Place: Mexico Publisher: Sociedad Mexicana de Psicología </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Given the mixed results in literature and the lack of human studies, a fear conditioning paradigm was used to evaluate whether the use of massive or moderate extinction trials have a differential effect on the recovery of extinguished fear, when assessed outside of the extinction context (an ABC renewal design), and after a delay (spontaneous recovery). 32 college students were randomly assigned to massive (80 conditioned stimulus presentations) and moderate extinction (10 conditioned stimulus presentations) groups. Results showed that massive extinction produced a significantly lower spontaneous recovery than moderate extinction, but that effect decreased when tested outside of the extinction context (renewal). These results question the applicability of this technique in the therapeutic context. (PsycINFO Database Record (c) 2017 APA, all rights reserved)</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/stepwise-480.webp 480w,/assets/img/publication_preview/stepwise-800.webp 800w,/assets/img/publication_preview/stepwise-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/stepwise.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="stepwise.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="navarro_stepwise_2016" class="col-sm-8"> <div class="title">Stepwise conceptualization in pigeons.</div> <div class="author"> Victor M. Navarro ,  and  Edward A. Wasserman </div> <div class="periodical"> <em>Journal of Experimental Psychology: Animal Learning and Cognition</em>, Dec 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>We explored the relation between concept learning and the number of training exemplars, programmed in a stepwise fashion. Eight pigeons (Columba livia) were trained via differential food reinforcement to peck 1 of 2 simultaneously displayed color images: benign or malignant human breast tissue samples. In each session, only 1 exemplar from each category was trained. If the learning criterion was achieved in 1 session, then those 2 exemplars were discarded and 2 new exemplars were trained in the next session. For the consistent group the reinforced category (benign or malignant stimuli for different birds) was maintained throughout all 24 training pairs, but for the inconsistent group the reinforced category was pseudorandomly changed from pair to pair. Pigeons in the consistent group evidenced striking gains in accuracy during the 1st few trials of training on new pairs (exceeding 90% correct over Pairs 10 –12), whereas pigeons in the inconsistent group evidenced reliably weaker gains in initial categorization accuracy (rising above only 70% correct after comparable training). Stepwise training involving as few as a dozen exemplars per category was thus sufficient to support robust concept learning in pigeons.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/contextual-cueing-480.webp 480w,/assets/img/publication_preview/contextual-cueing-800.webp 800w,/assets/img/publication_preview/contextual-cueing-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/contextual-cueing.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="contextual-cueing.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="couto_concept_2016" class="col-sm-8"> <div class="title">Concept learning without differential reinforcement in pigeons by means of contextual cueing.</div> <div class="author"> Kalliu C. Couto ,  Victor M. Navarro ,  Tatiana R. Smith , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Edward A. Wasserman' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Journal of Experimental Psychology: Animal Learning and Cognition</em>, Apr 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>How supervision is arranged can affect the way that humans learn concepts. Yet very little is known about the role that supervision plays in nonhuman concept learning. Prior research in pigeon concept learning has commonly used differential response–reinforcer procedures (involving high-level supervision) to support reliable discrimination and generalization involving from 4 to 16 concurrently presented photographic categories. In the present project, we used contextual cueing, a nondifferential reinforcement procedure (involving low-level supervision), to investigate concept learning in pigeons. We found that pigeons were faster to peck a target stimulus when 8 members from each of 4 categories of black-and-white photographs— dogs, trees, shoes, and keys— correctly cued its location than when they did not. This faster detection of the target also generalized to 4 untrained members from each of the 4 photographic categories. Our results thus pass the prime behavioral tests of conceptualization and suggest that high-level supervision is unnecessary to support concept learning in pigeons.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/extinction-480.webp 480w,/assets/img/publication_preview/extinction-800.webp 800w,/assets/img/publication_preview/extinction-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/extinction.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="extinction.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="gonzalez_preventing_2016" class="col-sm-8"> <div class="title">Preventing the recovery of extinguished ethanol tolerance</div> <div class="author"> Valeria V. González ,  Víctor Navarro ,  Gonzalo Miguez , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Ronald Betancourt, Mario A. Laborda' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Behavioural Processes</em>, Mar 2016 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/attention-480.webp 480w,/assets/img/publication_preview/attention-800.webp 800w,/assets/img/publication_preview/attention-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/attention.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="attention.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="vyazovska_stagewise_2016" class="col-sm-8"> <div class="title">Stagewise multidimensional visual discrimination by pigeons</div> <div class="author"> Olga V. Vyazovska ,  Victor M. Navarro ,  and  Edward A. Wasserman </div> <div class="periodical"> <em>Journal of the Experimental Analysis of Behavior</em>, Jul 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>We trained six pigeons in a stagewise Multiple Necessary Cues (MNC) go/no-go task to document the dynamics of discrimination learning involving increasingly complex visual stimuli. The compound stimuli were composed from four dimensions, each of which could assume either of two extreme values or their intermediate value: Shape, Size, Line Orientation, and Brightness. Starting with a stimulus composed entirely from intermediate values, we replaced those values with each of the two extreme dimensional values in four successive stages, thereby increasing the stimulus set from 2 in Stage 1 to 16 in Stage 4. In each stage, only one combination of values signaled food (S+), whereas the remaining combinations did not (S−s). We calculated the rate of pecking during the ﬁrst 15 s of each stimulus presentation and, in any given stage, training continued until the rate of responding to all of the S−s was less than 20% of the rate of responding to the S+. All pigeons successfully acquired the ﬁnal discrimination, suggesting that they attended to all of the dimensions relevant for the discrimination. We also replicated the key results of prior MNC studies: (1) the number of extreme dimensional values in each stage was positively related to the amount of training required for pigeons to acquire the discrimination; (2) attentional tradeoffs were most often observed when three or four dimensions were being trained; and (3) throughout training, the number of dimensional values in the S−s that differed from the S+ was positively related to their discriminability from S+.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cancer-480.webp 480w,/assets/img/publication_preview/cancer-800.webp 800w,/assets/img/publication_preview/cancer-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cancer.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cancer.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="krupinski_potential_2016" class="col-sm-8"> <div class="title">The potential of pigeons as surrogate observers in medical image perception studies</div> <div class="author"> Elizabeth A. Krupinski ,  Richard M. Levenson ,  <em>Victor Navarro</em> , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Edward A. Wasserman' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Medical Imaging 2016: Image Perception, Observer Performance, and Technology Assessment</em> , Mar 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Assessment of medical image quality and how changes in image appearance impact performance are critical but assessment can be expensive and time-consuming. Could an animal (pigeon) observer with well-known visual skills and documented ability to distinguish complex visual stimuli serve as a surrogate for the human observer? Using sets of whole slide pathology (WSI) and mammographic images we trained pigeons (cohorts of 4) to detect and/or classify lesions in medical images. Standard training methods were used. A chamber equipped with a 15’ display with a resistive touchscreen was used to display the images and record responses (pecks). Pigeon pellets were dispensed for correct responses. The pigeons readily learned to distinguish benign from malignant breast cancer histopathology in WSI (mean % correct responses rose 50% to 85% over 15 days) and generalized readily from 4X to 10X and 20X magnifications; to detect microcalcifications (mean % correct responses rose 50% to over 85% over 25 days); to distinguish benign from malignant breast masses (3 of 4 birds learned this task to around 80% and 60% over 10 days); and ignore compression artifacts in WSI (performance with uncompressed slides averaged 95% correct; 15:1 and 27:1 compression slides averaged 92% and 90% correct). Pigeons models may help us better understand medical image perception and may be useful in quality assessment by serving as surrogate observers for certain types of studies.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2015</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/cancer-480.webp 480w,/assets/img/publication_preview/cancer-800.webp 800w,/assets/img/publication_preview/cancer-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/cancer.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="cancer.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="levenson_pigeons_2015" class="col-sm-8"> <div class="title">Pigeons (Columba livia) as Trainable Observers of Pathology and Radiology Breast Cancer Images</div> <div class="author"> Richard M. Levenson ,  Elizabeth A. Krupinski ,  Victor M. Navarro , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Edward A. Wasserman' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>PLOS ONE</em>, Nov 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Pathologists and radiologists spend years acquiring and refining their medically essential visual skills, so it is of considerable interest to understand how this process actually unfolds and what image features and properties are critical for accurate diagnostic performance. Key insights into human behavioral tasks can often be obtained by using appropriate animal models. We report here that pigeons (Columba livia)—which share many visual system properties with humans—can serve as promising surrogate observers of medical images, a capability not previously documented. The birds proved to have a remarkable ability to distinguish benign from malignant human breast histopathology after training with differential food reinforcement; even more importantly, the pigeons were able to generalize what they had learned when confronted with novel image sets. The birds’ histological accuracy, like that of humans, was modestly affected by the presence or absence of color as well as by degrees of image compression, but these impacts could be ameliorated with further training. Turning to radiology, the birds proved to be similarly capable of detecting cancer-relevant microcalcifications on mammogram images. However, when given a different (and for humans quite difficult) task—namely, classification of suspicious mammographic densities (masses)—the pigeons proved to be capable only of image memorization and were unable to successfully generalize when shown novel examples. The birds’ successes and difficulties suggest that pigeons are well-suited to help us better understand human medical image perception, and may also prove useful in performance assessment and development of medical imaging hardware, image processing, and image analysis tools.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2014</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/sleep-480.webp 480w,/assets/img/publication_preview/sleep-800.webp 800w,/assets/img/publication_preview/sleep-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/sleep.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sleep.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="borquez_sleep_2014" class="col-sm-8"> <div class="title">Sleep enhances inhibitory behavioral control in discrimination learning in rats</div> <div class="author"> Margarita Borquez ,  Jan Born ,  <em>Victor Navarro</em> , and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Ronald Betancourt, Marion Inostroza' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Experimental Brain Research</em>, May 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Sleep supports the consolidation of memory, and it has been proposed that this enhancing effect of sleep pertains in particular to memories which are encoded under control of prefrontal–hippocampal circuitry into an episodic memory system. Furthermore, repeated reactivation and transformation of such memories during sleep are thought to promote the de-contextualization of these memories. Here, we aimed to establish a behavioral model for the study of such sleep-dependent system consolidation in rats, using a go/nogo conditional discrimination learning task known to essentially depend on prefrontal–hippocampal function. Different groups of rats were trained to criterion on this task and, then, subjected to 80-min retention intervals filled with spontaneous morning sleep, sleep deprivation, or spontaneous evening wakefulness. In a subsequent test phase, the speed of relearning of the discrimination task was examined as indicator of memory, whereby rats were either tested in the same context as during training or in a different context. Sleep promoted relearning of the conditional discrimination task, and this effect was similar for testing memory in the same or different context (p \textless 0.001). Independent of sleep and wakefulness during the retention interval, animals showed faster relearning when tested in the same context as during learning, compared with testing in a different context (p \textless 0.001). The benefitting effect of sleep on discrimination learning was primarily due to an enhancing effect on response suppression during the nogo stimulus. We infer from these results that sleep enhances memory for inhibitory behavioral control in a generalized context-independent manner and thereby might eventually also contribute to the abstraction of schema-like representations.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Victor M. Navarro. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-D5KK6KWT5G"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-D5KK6KWT5G");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>